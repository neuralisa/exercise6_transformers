This week, try to get access to jupyterhub on TU Wien and implement a benchmark to evaluate t5-small and t5-medium models on a subset of the translation dataset you used in the previous exercise.
Evaluate both german to english and english to german. What do you observe?
Is it possible to fine tune the T5 small model on the de-en dataset to improve it's bleu score? 
Upcoming: Fine tune T5 to create a tags classifier (the repository will be updated).
